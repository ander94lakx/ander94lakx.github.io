<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>python on Walk on the Byte Side</title><link>https://ander94lakx.github.io/tags/python/</link><description>Recent content in python on Walk on the Byte Side</description><generator>Hugo -- gohugo.io</generator><language>en</language><managingEditor>ander@protonmail.com (Ander Granado)</managingEditor><webMaster>ander@protonmail.com (Ander Granado)</webMaster><lastBuildDate>Sun, 13 Feb 2022 00:00:00 +0000</lastBuildDate><atom:link href="https://ander94lakx.github.io/tags/python/index.xml" rel="self" type="application/rss+xml"/><item><title>How to get your Top tracks (or whatever info) out of your Spotify account</title><link>https://ander94lakx.github.io/blog/2022-02-13-spotify-data-top-songs/</link><pubDate>Sun, 13 Feb 2022 00:00:00 +0000</pubDate><author>ander@protonmail.com (Ander Granado)</author><guid>https://ander94lakx.github.io/blog/2022-02-13-spotify-data-top-songs/</guid><description>I&amp;rsquo;m heavily into web scraping, I know, but this time it&amp;rsquo;s something a bit different. It&amp;rsquo;s not your typical web scraping; it&amp;rsquo;s a small example of how to extract information about your own data. You can get some very interesting insights from the data we generate daily. For instance, in my case, I use Spotify daily to listen to music. I never leave home without headphones, and I even wear them in the bathroom, so I generate a certain amount of data while using Spotify.</description><content>&lt;p>I&amp;rsquo;m heavily into web scraping, I know, but this time it&amp;rsquo;s something a bit different. It&amp;rsquo;s not your typical web scraping; it&amp;rsquo;s a small example of how to extract information about your own data. You can get some very interesting insights from the data we generate daily. For instance, in my case, I use Spotify daily to listen to music. I never leave home without headphones, and I even wear them in the bathroom, so I generate a certain amount of data while using Spotify.&lt;/p>
&lt;h2 id="downloading-your-information">Downloading Your Information&lt;/h2>
&lt;p>Many applications allow users to download the information they generate. For most European citizens, it&amp;rsquo;s worth mentioning that practically all applications enable this, as it&amp;rsquo;s a right granted by &lt;a href="https://support.spotify.com/es/article/gdpr-article-15-information/">Article 15&lt;/a> of the European Union&amp;rsquo;s GDPR. This means that nearly all online services let you download a copy of your data, at least in this part of the world.&lt;/p>
&lt;p>This is interesting because it lets you extract information that the applications and services have about you but don&amp;rsquo;t display through their interfaces. For instance, in the case of Spotify, you can download your &lt;a href="https://support.spotify.com/es/article/data-rights-and-privacy-settings/">main data&lt;/a>, including things like your playback history for the last year. It&amp;rsquo;s important to note that in Spotify&amp;rsquo;s case, the data you get with their tool for downloading data isn&amp;rsquo;t complete, but you can request absolutely everything by &lt;a href="mailto:privacy@spotify.com">contacting them directly&lt;/a>.&lt;/p>
&lt;p>This way, something that can&amp;rsquo;t be seen within the Spotify app can be done through the data they allow you to download. Typically, this kind of data comes in formats like JSON or XML to interact with it programmatically. Sometimes, they even provide options for the format, as is the case with Instagram, where you can download a version in HTML (useful for having a backup) or in JSON (if you want to work with the data).&lt;/p>
&lt;h2 id="extracting-most-listened-content-from-spotifys-information">Extracting Most Listened Content from Spotify&amp;rsquo;s Information&lt;/h2>
&lt;p>Getting back to Spotify, you can extract a lot of information from this data. In my case, as a starting point to tinker with the data, I&amp;rsquo;ve simply programmed a script to see what my top listened songs and artists are. Some might think that Spotify already provides this in their annual &amp;ldquo;wrapped&amp;rdquo; summaries or in some generated playlists. In part, this is true, but it&amp;rsquo;s given to you &amp;ldquo;their way.&amp;rdquo; Meaning, you might know your Top 5 most listened-to artists, but not the Top 10, or how many times you&amp;rsquo;ve listened to a certain artist, or how much you&amp;rsquo;ve listened to an artist that&amp;rsquo;s not in your top list, etc. The power of having all the data in your hands is that you can &lt;strong>extract the information you want and how you want it&lt;/strong>.&lt;/p>
&lt;p>In this case, I&amp;rsquo;ve tried with basic data, which has limited information. If you request the copy with all the information, you can obtain a lot more data. In Spotify&amp;rsquo;s &lt;a href="https://support.spotify.com/es/article/understanding-my-data/">documentation&lt;/a>, you can see exactly what data they offer in both cases. For the case of basic data, Spotify provides a zip file with a handful of JSON files.&lt;/p>
&lt;p>&lt;img src="https://ander94lakx.github.io/static/images/spotify_data.png" alt="Spotify Data" title="Basic data provided by Spotify">&lt;/p>
&lt;p>Among the files provided by Spotify, the ones relevant for this PoC are named &lt;code>StreamingHistory[x].json&lt;/code>. These files contain the playback history. The information regarding the song is quite limited but enough to identify it. The file has a format like the following:&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-json" data-lang="json">&lt;span style="display:flex;">&lt;span>[
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> {
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">&amp;#34;endTime&amp;#34;&lt;/span> : &lt;span style="color:#e6db74">&amp;#34;2021-02-05 11:10&amp;#34;&lt;/span>,
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">&amp;#34;artistName&amp;#34;&lt;/span> : &lt;span style="color:#e6db74">&amp;#34;Hüsker Dü&amp;#34;&lt;/span>,
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">&amp;#34;trackName&amp;#34;&lt;/span> : &lt;span style="color:#e6db74">&amp;#34;Don&amp;#39;t Want to Know If You Are Lonely&amp;#34;&lt;/span>,
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">&amp;#34;msPlayed&amp;#34;&lt;/span> : &lt;span style="color:#ae81ff">212426&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> },
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> {
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">&amp;#34;endTime&amp;#34;&lt;/span> : &lt;span style="color:#e6db74">&amp;#34;2021-02-05 12:16&amp;#34;&lt;/span>,
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">&amp;#34;artistName&amp;#34;&lt;/span> : &lt;span style="color:#e6db74">&amp;#34;Queens of the Stone Age&amp;#34;&lt;/span>,
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">&amp;#34;trackName&amp;#34;&lt;/span> : &lt;span style="color:#e6db74">&amp;#34;Go With The Flow&amp;#34;&lt;/span>,
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">&amp;#34;msPlayed&amp;#34;&lt;/span> : &lt;span style="color:#ae81ff">4890&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> },
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> {
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">&amp;#34;endTime&amp;#34;&lt;/span> : &lt;span style="color:#e6db74">&amp;#34;2021-02-05 12:23&amp;#34;&lt;/span>,
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">&amp;#34;artistName&amp;#34;&lt;/span> : &lt;span style="color:#e6db74">&amp;#34;Queens of the Stone Age&amp;#34;&lt;/span>,
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">&amp;#34;trackName&amp;#34;&lt;/span> : &lt;span style="color:#e6db74">&amp;#34;Go With The Flow&amp;#34;&lt;/span>,
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">&amp;#34;msPlayed&amp;#34;&lt;/span> : &lt;span style="color:#ae81ff">190646&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> },
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> {
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">&amp;#34;endTime&amp;#34;&lt;/span> : &lt;span style="color:#e6db74">&amp;#34;2021-02-05 12:24&amp;#34;&lt;/span>,
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">&amp;#34;artistName&amp;#34;&lt;/span> : &lt;span style="color:#e6db74">&amp;#34;Queens of the Stone Age&amp;#34;&lt;/span>,
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">&amp;#34;trackName&amp;#34;&lt;/span> : &lt;span style="color:#e6db74">&amp;#34;Make It Wit Chu&amp;#34;&lt;/span>,
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">&amp;#34;msPlayed&amp;#34;&lt;/span> : &lt;span style="color:#ae81ff">19403&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> },
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>And so on infinitely. It provides the timestamp, song name, artist, and playback time. This last piece is interesting because you can set a minimum threshold to consider a song as listened, for example. You can also play around with the timestamp to see when you&amp;rsquo;ve listened to more or less music. The possibilities are vast.&lt;/p>
&lt;p>With this, the script I&amp;rsquo;ve created to get the top most listened songs and artists is as follows:&lt;/p>
&lt;p>&lt;code>gist:ander94lakx/63776dacd6e986d935b9f01fff755921#spotify_top_songs_and_artists.py&lt;/code>&lt;/p>
&lt;p>I don&amp;rsquo;t think it&amp;rsquo;s worth going into detail about the code since it&amp;rsquo;s quite simple, and most of it is self-explanatory. It&amp;rsquo;s basically a function that performs a series of steps that can be summarized as follows:&lt;/p>
&lt;ol>
&lt;li>Manage an argument to configure the size of the Top.&lt;/li>
&lt;li>Read the files and load JSON information into dictionaries.&lt;/li>
&lt;li>Perform calculations on the loaded information.&lt;/li>
&lt;li>Sort, prepare, and display the top listened songs and artists.&lt;/li>
&lt;/ol>
&lt;p>Certainly, there might be many ways to improve it. You could unify the part where you fetch the data with the part where you calculate the playbacks, but I wanted to keep it separate to make it easier to understand. Additionally, my Python skills aren&amp;rsquo;t perfect, and some things with sets (among many others) could probably be done better.&lt;/p>
&lt;h2 id="conclusions">Conclusions&lt;/h2>
&lt;p>Having access to the data you generate in an application enables you to extract a lot of information. Applications and services know this and use the data to extract insights for their benefit. At the very least, since they process user information, they should allow users to do the same.&lt;/p>
&lt;p>Moreover, this allows you to extend the capabilities offered by the applications themselves. In Spotify&amp;rsquo;s case, you could analyze the music you listen to, how you listen to it, or how your listening habits have changed over time – things Spotify doesn&amp;rsquo;t offer its users. Similarly, you can do more of the same with other applications. The ability to obtain your own information is the first step to being able to handle it in your own way.&lt;/p>
&lt;p>There are surely a thousand examples of interesting cases where this type of application-generated information can be used. If you&amp;rsquo;re reading this, I invite you to download your information from the applications you use, take a look, and think about the interesting uses you can make of it. Information is power, and users should have that power too.&lt;/p>
&lt;p>Don&amp;rsquo;t stop downloading what belongs to you!&lt;/p>
&lt;p>Happy hacking!&lt;/p></content></item><item><title>How to automate flat-hunting with a Telegram bot</title><link>https://ander94lakx.github.io/blog/2022-02-05-bot-telegram-find-flat/</link><pubDate>Sat, 05 Feb 2022 00:00:00 +0000</pubDate><author>ander@protonmail.com (Ander Granado)</author><guid>https://ander94lakx.github.io/blog/2022-02-05-bot-telegram-find-flat/</guid><description>I am looking for a flat. Looking for a flat is a shitty process. There is a strangely small number of flats in my city and the ones that are available disappear quickly.
I&amp;rsquo;m too lazy to spend all my time looking for a flat. It&amp;rsquo;s not really that complicated, but sometimes I&amp;rsquo;m busy and I forget to look that day, or I&amp;rsquo;m out and it&amp;rsquo;s more hassle with my phone.</description><content>&lt;p>I am looking for a flat. Looking for a flat is a shitty process. There is a strangely small number of flats in my city and the ones that are available disappear quickly.&lt;/p>
&lt;p>I&amp;rsquo;m too lazy to spend all my time looking for a flat. It&amp;rsquo;s not really that complicated, but sometimes I&amp;rsquo;m busy and I forget to look that day, or I&amp;rsquo;m out and it&amp;rsquo;s more hassle with my phone.&lt;/p>
&lt;p>I&amp;rsquo;ve been wanting to make a Telegram bot for a while now. I didn&amp;rsquo;t know exactly what to do, but the other day I got an idea and I created a bot that tells me about the available flats in my city.&lt;/p>
&lt;p>&lt;img src="https://ander94lakx.github.io/static/images/scraping_telegram_python_bot.jpg" alt="Scraping Python Telegram bot" title="Scraping Telegram bot made with Python">&lt;/p>
&lt;p>There are two parts involved in this. One is the web scraping part. This is basically automating the extraction of information from websites. Nowadays almost everything is done from the internet and looking for a flat is not going to be any different. Practically all local real estate agencies and individuals who rent flats post their ads on certain platforms (in Spain maily in platforms such as Idealista or Fotocasa), so by consulting there I can see what new options are appearing. It&amp;rsquo;s basically what I was doing so far manually and without enough constancy. Automating it with web scraping allows me to get all that information at a glance.&lt;/p>
&lt;p>The other part is the Telegram bot. Until two days ago I had no idea how it worked. Basically Telegram has a great API so you can do everything with it. You can create bots that run anywhere to communicate directly with users, write in chats or channels and do a lot of things. There is also a very good &lt;a href="https://github.com/python-telegram-bot/python-telegram-bot">wrapper for Python&lt;/a> that you can use to interact with the API from Python in a very simple way.&lt;/p>
&lt;h2 id="part-1-web-scraping-with-selenium">Part 1: web scraping with Selenium&lt;/h2>
&lt;p>It&amp;rsquo;s not the first time I have done web scraping. Some time ago I made a script that allowed to scrape instagram to download all the images of a user. You can have a look at the &lt;a href="https://ander94lakx.github.io/blog/2020-04-25-instagram-bot-python/">post&lt;/a> I made or the &lt;a href="https://github.com/ander94lakx/InstaBot">code&lt;/a> of the bot (it&amp;rsquo;s a bot, but it&amp;rsquo;s not a Telegram bot).&lt;/p>
&lt;p>When I made that script I used &lt;a href="https://www.selenium.dev/">Selenium&lt;/a>, which is probably the best web scraping tool out there. It&amp;rsquo;s not just for that, but it allows you to automate browser operations. With this, you can open websites, browse them, perform actions and extract information from them programmatically. This is much better than directly sending a request with a request handling library, because by actually launching an instance of a browser, you can bypass measures that some websites have in place to block automated mechanisms. The downside is that, since you have to open a browser, you can&amp;rsquo;t run it in an environment that doesn&amp;rsquo;t have a screen (although this can be easily solved with screen-simulating libraries such as &lt;a href="https://pypi.org/project/PyVirtualDisplay/">PyVirtualDisplay&lt;/a>).&lt;/p>
&lt;p>With the tools ready and installed, all that remains is to use Selenium to start web scraping. The simpler the scraping the better. In this case, instead of passing the base URL of a flat search site, you can extract the URLs with the parameters to filter the search. In my case, and using Idealista as an example, the URL would be something like this:&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-bash" data-lang="bash">&lt;span style="display:flex;">&lt;span>https://www.idealista.com/alquiler-viviendas/vitoria-gasteiz-alava/?ordenado-por&lt;span style="color:#f92672">=&lt;/span>precios-asc
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>As you can see, I am already filtering by my city, and apart from that, I&amp;rsquo;m sorting by price to display the cheapest ones first (there&amp;rsquo;s not much money around here). This could be narrowed down even further. Since most websites of this kind use search parameters in the URL itself (i.e. query parameters, very useful for save as bookmarks later), a lot of scraping work can be saved by simply targeting the endpoint with specific query parameters.&lt;/p>
&lt;p>&lt;img src="https://ander94lakx.github.io/static/images/idealista_web.png" alt="Idealista Results" title="Search results using Idealista">&lt;/p>
&lt;p>With that in mind, I&amp;rsquo;ve created a simple function that scrapes that page and retrieves flat-related info. I&amp;rsquo;ve also included an option to filter by price (although this is something that can also be done through the URL). The code is as follows:&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-python" data-lang="python">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#66d9ef">def&lt;/span> &lt;span style="color:#a6e22e">scrap_idealista&lt;/span>(max_price):
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> driver &lt;span style="color:#f92672">=&lt;/span> initialize_driver(IDEALISTA_URL)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> scroll_down_and_up(driver)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#75715e"># Be kind and accept the cookies&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#66d9ef">try&lt;/span>:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> driver&lt;span style="color:#f92672">.&lt;/span>find_element_by_id(&lt;span style="color:#e6db74">&amp;#39;didomi-notice-agree-button&amp;#39;&lt;/span>)&lt;span style="color:#f92672">.&lt;/span>click()
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#66d9ef">except&lt;/span>:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#66d9ef">pass&lt;/span> &lt;span style="color:#75715e"># No cookies button, no problem!&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#75715e"># Find each flat element&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> elements &lt;span style="color:#f92672">=&lt;/span> driver&lt;span style="color:#f92672">.&lt;/span>find_element_by_xpath(&lt;span style="color:#e6db74">&amp;#39;//*[@id=&amp;#34;main-content&amp;#34;]&amp;#39;&lt;/span>)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> items &lt;span style="color:#f92672">=&lt;/span> elements&lt;span style="color:#f92672">.&lt;/span>find_elements_by_class_name(&lt;span style="color:#e6db74">&amp;#39;item-multimedia-container&amp;#39;&lt;/span>)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> flat_list &lt;span style="color:#f92672">=&lt;/span> []
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#66d9ef">for&lt;/span> item &lt;span style="color:#f92672">in&lt;/span> items:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#75715e"># Get the link for that flat&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> link &lt;span style="color:#f92672">=&lt;/span> item&lt;span style="color:#f92672">.&lt;/span>find_element_by_xpath(&lt;span style="color:#e6db74">&amp;#39;./div/a[@href]&amp;#39;&lt;/span>)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> link &lt;span style="color:#f92672">=&lt;/span> link&lt;span style="color:#f92672">.&lt;/span>get_attribute(&lt;span style="color:#e6db74">&amp;#39;href&amp;#39;&lt;/span>)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#75715e"># Get the price for that flat&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> result &lt;span style="color:#f92672">=&lt;/span> re&lt;span style="color:#f92672">.&lt;/span>search(&lt;span style="color:#e6db74">&amp;#39;.*&lt;/span>&lt;span style="color:#ae81ff">\\&lt;/span>&lt;span style="color:#e6db74">n(.*)€\/mes&amp;#39;&lt;/span>, item&lt;span style="color:#f92672">.&lt;/span>text)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> price_str &lt;span style="color:#f92672">=&lt;/span> result&lt;span style="color:#f92672">.&lt;/span>group(&lt;span style="color:#ae81ff">1&lt;/span>)&lt;span style="color:#f92672">.&lt;/span>replace(&lt;span style="color:#e6db74">&amp;#39;.&amp;#39;&lt;/span>, &lt;span style="color:#e6db74">&amp;#39;&amp;#39;&lt;/span>)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> price &lt;span style="color:#f92672">=&lt;/span> int(price_str)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#66d9ef">if&lt;/span> price &lt;span style="color:#f92672">&amp;lt;=&lt;/span> max_price:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> flat_list&lt;span style="color:#f92672">.&lt;/span>append({
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#e6db74">&amp;#39;link&amp;#39;&lt;/span>: link,
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#e6db74">&amp;#39;price&amp;#39;&lt;/span>: price,
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#e6db74">&amp;#39;image&amp;#39;&lt;/span>: item&lt;span style="color:#f92672">.&lt;/span>screenshot_as_png,
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#e6db74">&amp;#39;image_name&amp;#39;&lt;/span>: item&lt;span style="color:#f92672">.&lt;/span>id &lt;span style="color:#f92672">+&lt;/span> &lt;span style="color:#e6db74">&amp;#39;.png&amp;#39;&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> })
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> driver&lt;span style="color:#f92672">.&lt;/span>quit()
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#66d9ef">return&lt;/span> flat_list
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>Overall, it&amp;rsquo;s quite straightforward to comprehend. First and foremost, the Selenium driver is loaded, and the page is scrolled through entirely. Initially, the web page is loaded to have everything ready to start the search. The scrolling is done because, sometimes, results are loaded as you scroll, so performing a quick scroll before extracting information ensures that all results are actually loaded.&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-python" data-lang="python">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#66d9ef">def&lt;/span> &lt;span style="color:#a6e22e">initialize_driver&lt;/span>(url):
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> driver &lt;span style="color:#f92672">=&lt;/span> webdriver&lt;span style="color:#f92672">.&lt;/span>Chrome(executable_path&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#e6db74">&amp;#39;./chromedriver.exe&amp;#39;&lt;/span>)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> driver&lt;span style="color:#f92672">.&lt;/span>get(url)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> sleep(&lt;span style="color:#ae81ff">2&lt;/span>)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> driver&lt;span style="color:#f92672">.&lt;/span>set_window_position(&lt;span style="color:#ae81ff">0&lt;/span>,&lt;span style="color:#ae81ff">0&lt;/span>)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> driver&lt;span style="color:#f92672">.&lt;/span>set_window_size(&lt;span style="color:#ae81ff">1920&lt;/span>, &lt;span style="color:#ae81ff">1080&lt;/span>)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#66d9ef">return&lt;/span> driver
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>Using Selenium is quite straightforward. In this case, I&amp;rsquo;m using the Chrome driver, which I have right in my directory for convenience. After that, I load the URL and set up the window to have a decent size. This is important because elements will be positioned differently depending on the window size. Responsive design is great, but it&amp;rsquo;s one of the worst enemies of a scraper. So, setting a consistent resolution is important to consistently obtain the same results.&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-python" data-lang="python">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#66d9ef">def&lt;/span> &lt;span style="color:#a6e22e">scroll_down_and_up&lt;/span>(driver):
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> driver&lt;span style="color:#f92672">.&lt;/span>execute_script(&lt;span style="color:#e6db74">&amp;#39;window.scrollTo(0, document.body.scrollHeight);&amp;#39;&lt;/span>)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> sleep(&lt;span style="color:#ae81ff">2&lt;/span>)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> driver&lt;span style="color:#f92672">.&lt;/span>execute_script(&lt;span style="color:#e6db74">&amp;#39;window.scrollTo(0, 0);&amp;#39;&lt;/span>)
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>Regarding scrolling, there&amp;rsquo;s nothing special here. Just a bit of JS and we&amp;rsquo;re good to go.&lt;/p>
&lt;p>The real deal comes next. Firstly, accepting cookies to navigate the site smoothly and avoid any oddities. This is where the power of Selenium starts to shine.&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-python" data-lang="python">&lt;span style="display:flex;">&lt;span>driver&lt;span style="color:#f92672">.&lt;/span>find_element_by_id(&lt;span style="color:#e6db74">&amp;#39;didomi-notice-agree-button&amp;#39;&lt;/span>)&lt;span style="color:#f92672">.&lt;/span>click()
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>The element with that ID is selected, in this case a button, and then clicked. The next step is to find the elements with the flat information. Those little cards that appear in a list. Like all elements on a website, they have classes or attributes that identify them.&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-python" data-lang="python">&lt;span style="display:flex;">&lt;span>elements &lt;span style="color:#f92672">=&lt;/span> driver&lt;span style="color:#f92672">.&lt;/span>find_element_by_xpath(&lt;span style="color:#e6db74">&amp;#39;//*[@id=&amp;#34;main-content&amp;#34;]&amp;#39;&lt;/span>)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>items &lt;span style="color:#f92672">=&lt;/span> elements&lt;span style="color:#f92672">.&lt;/span>find_elements_by_class_name(&lt;span style="color:#e6db74">&amp;#39;item-multimedia-container&amp;#39;&lt;/span>)
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>In this case, I&amp;rsquo;ve performed searches using XPath and through class names. If you look at the Idealista website, you can extract this information. It will be different on each website. The great thing about Selenium is that it lets you retrieve elements and then search within them. This way, you can proceed step by step until you reach your intended target.&lt;/p>
&lt;p>&lt;img src="https://ander94lakx.github.io/static/images/idealista_scraping.png" alt="Idealista Scrapping" title="Elements to find with Selenium">&lt;/p>
&lt;p>Searching through IDs and classes is simple. Searching through XPath is more complex but very powerful. This process can be simplified with an extension like &lt;a href="https://github.com/trembacz/xpath-finder">xPath Finder&lt;/a>, which allows you to obtain the XPath of any element on a webpage.&lt;/p>
&lt;p>With that, we now have a list of items, which are each of those little cards. At this point, the next step is to extract the information we want to retrieve.&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-python" data-lang="python">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#66d9ef">for&lt;/span> item &lt;span style="color:#f92672">in&lt;/span> items:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#75715e"># Get the link for that flat&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> link &lt;span style="color:#f92672">=&lt;/span> item&lt;span style="color:#f92672">.&lt;/span>find_element_by_xpath(&lt;span style="color:#e6db74">&amp;#39;./div/a[@href]&amp;#39;&lt;/span>)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> link &lt;span style="color:#f92672">=&lt;/span> link&lt;span style="color:#f92672">.&lt;/span>get_attribute(&lt;span style="color:#e6db74">&amp;#39;href&amp;#39;&lt;/span>)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#75715e"># Get the price for that flat&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> result &lt;span style="color:#f92672">=&lt;/span> re&lt;span style="color:#f92672">.&lt;/span>search(&lt;span style="color:#e6db74">&amp;#39;.*&lt;/span>&lt;span style="color:#ae81ff">\\&lt;/span>&lt;span style="color:#e6db74">n(.*)€\/mes&amp;#39;&lt;/span>, item&lt;span style="color:#f92672">.&lt;/span>text)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> price_str &lt;span style="color:#f92672">=&lt;/span> result&lt;span style="color:#f92672">.&lt;/span>group(&lt;span style="color:#ae81ff">1&lt;/span>)&lt;span style="color:#f92672">.&lt;/span>replace(&lt;span style="color:#e6db74">&amp;#39;.&amp;#39;&lt;/span>, &lt;span style="color:#e6db74">&amp;#39;&amp;#39;&lt;/span>)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> price &lt;span style="color:#f92672">=&lt;/span> int(price_str)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#66d9ef">if&lt;/span> price &lt;span style="color:#f92672">&amp;lt;=&lt;/span> max_price:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> flat_list&lt;span style="color:#f92672">.&lt;/span>append({
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#e6db74">&amp;#39;link&amp;#39;&lt;/span>: link,
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#e6db74">&amp;#39;price&amp;#39;&lt;/span>: price,
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#e6db74">&amp;#39;image&amp;#39;&lt;/span>: item&lt;span style="color:#f92672">.&lt;/span>screenshot_as_png
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> })
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>There are many ways to achieve this. Selenium allows you to extract the element as an image, which can be useful for sending it in that format later. In my case, I extract the apartment as an image (to send it via Telegram), the price (to check that it doesn&amp;rsquo;t exceed the set limit), and the link (to include alongside each image for accessing the apartments I&amp;rsquo;m interested in). The image name allows me to manage the images for sending them through Telegram.&lt;/p>
&lt;p>And that&amp;rsquo;s it, it&amp;rsquo;s that simple. Now, all that&amp;rsquo;s left is to send this information through Telegram.&lt;/p>
&lt;h2 id="part-2-creating-a-telegram-bot">Part 2: creating a Telegram bot&lt;/h2>
&lt;p>Crear un bot de Telegram es tan sencillo como usar &lt;a href="https://t.me/botfather">BotFather&lt;/a>, el bot que te permite crear bots. Tras crear un bot con él, te da un token que es lo que te permite hacer lo que quieras con la API. La creación del bot es trivial, consiste en hablar con el bot.&lt;/p>
&lt;p>Una vez teniendo un token se puede hacer uso del &lt;a href="https://github.com/python-telegram-bot/python-telegram-bot">wrapper para Python&lt;/a> que he mencionado. Instalar con &lt;code>pip&lt;/code> y listo. Del wrapper he utilizado lo siguiente:&lt;/p>
&lt;p>Creating a Telegram bot is as simple as using &lt;a href="https://t.me/botfather">BotFather&lt;/a>, the bot that allows you to create bots. After creating a bot with it, you will receive a token that enables you to interact with the API. Bot creation is straightforward; it involves having a conversation with the bot.&lt;/p>
&lt;p>Once you have a token, you can utilize the &lt;a href="https://github.com/python-telegram-bot/python-telegram-bot">Python wrapper&lt;/a> I mentioned. Install it using pip, and you&amp;rsquo;re all set. From the wrapper, I&amp;rsquo;ve used the following features:&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-python" data-lang="python">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#f92672">import&lt;/span> telegram
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#f92672">from&lt;/span> telegram &lt;span style="color:#f92672">import&lt;/span> Bot, Update
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#f92672">from&lt;/span> telegram.ext &lt;span style="color:#f92672">import&lt;/span> Updater
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#f92672">from&lt;/span> telegram.ext &lt;span style="color:#f92672">import&lt;/span> CallbackContext
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#f92672">from&lt;/span> telegram.ext &lt;span style="color:#f92672">import&lt;/span> CommandHandler
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>With it, you can instantiate the bot using the obtained token and create callbacks that allow you to easily listen for commands.&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-python" data-lang="python">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#66d9ef">def&lt;/span> &lt;span style="color:#a6e22e">init&lt;/span>():
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#66d9ef">with&lt;/span> open(&lt;span style="color:#e6db74">&amp;#39;token.txt&amp;#39;&lt;/span>) &lt;span style="color:#66d9ef">as&lt;/span> f:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> token &lt;span style="color:#f92672">=&lt;/span> f&lt;span style="color:#f92672">.&lt;/span>read()
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> updater &lt;span style="color:#f92672">=&lt;/span> Updater(token&lt;span style="color:#f92672">=&lt;/span>token, use_context&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#66d9ef">True&lt;/span>)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> dispatcher &lt;span style="color:#f92672">=&lt;/span> updater&lt;span style="color:#f92672">.&lt;/span>dispatcher
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> logging&lt;span style="color:#f92672">.&lt;/span>basicConfig(format&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#e6db74">&amp;#39;&lt;/span>&lt;span style="color:#e6db74">%(asctime)s&lt;/span>&lt;span style="color:#e6db74"> - &lt;/span>&lt;span style="color:#e6db74">%(name)s&lt;/span>&lt;span style="color:#e6db74"> - &lt;/span>&lt;span style="color:#e6db74">%(levelname)s&lt;/span>&lt;span style="color:#e6db74"> - &lt;/span>&lt;span style="color:#e6db74">%(message)s&lt;/span>&lt;span style="color:#e6db74">&amp;#39;&lt;/span>,
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> level&lt;span style="color:#f92672">=&lt;/span>logging&lt;span style="color:#f92672">.&lt;/span>INFO)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> dispatcher&lt;span style="color:#f92672">.&lt;/span>add_handler(CommandHandler(&lt;span style="color:#e6db74">&amp;#39;start&amp;#39;&lt;/span>, start))
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> dispatcher&lt;span style="color:#f92672">.&lt;/span>add_handler(CommandHandler(&lt;span style="color:#e6db74">&amp;#39;bilatu&amp;#39;&lt;/span>, bilatu))
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> dispatcher&lt;span style="color:#f92672">.&lt;/span>add_handler(CommandHandler(&lt;span style="color:#e6db74">&amp;#39;idealista&amp;#39;&lt;/span>, idealista))
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> dispatcher&lt;span style="color:#f92672">.&lt;/span>add_handler(CommandHandler(&lt;span style="color:#e6db74">&amp;#39;fotocasa&amp;#39;&lt;/span>, fotocasa))
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> updater&lt;span style="color:#f92672">.&lt;/span>start_polling()
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>That function is executed when the script starts. I fetch the token from a separate file and create the bot. In the code, you can see that four handlers are created. These are the commands that can be executed with the bot. In this case, they are &lt;code>/start&lt;/code>, &lt;code>/bilatu&lt;/code> (which means &amp;ldquo;search&amp;rdquo; in Basque), &lt;code>/idealista&lt;/code>, and &lt;code>/fotocasa&lt;/code>. This way, you can search in all sources or just in a specific one. The functions called with the callbacks are the following:&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-python" data-lang="python">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#66d9ef">def&lt;/span> &lt;span style="color:#a6e22e">bilatu&lt;/span>(update: Update, context: CallbackContext):
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> scrap(update, context, &lt;span style="color:#e6db74">&amp;#39;all&amp;#39;&lt;/span>)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#66d9ef">def&lt;/span> &lt;span style="color:#a6e22e">idealista&lt;/span>(update: Update, context: CallbackContext):
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> scrap(update, context, &lt;span style="color:#e6db74">&amp;#39;idealista&amp;#39;&lt;/span>)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#66d9ef">def&lt;/span> &lt;span style="color:#a6e22e">fotocasa&lt;/span>(update: Update, context: CallbackContext):
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> scrap(update, context, &lt;span style="color:#e6db74">&amp;#39;fotocasa&amp;#39;&lt;/span>)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#66d9ef">def&lt;/span> &lt;span style="color:#a6e22e">scrap&lt;/span>(update: Update, context: CallbackContext, site):
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> send_initial_message(context, update)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> max_price &lt;span style="color:#f92672">=&lt;/span> get_max_price(context)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> flat_list &lt;span style="color:#f92672">=&lt;/span> []
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#66d9ef">if&lt;/span> site &lt;span style="color:#f92672">in&lt;/span> { &lt;span style="color:#e6db74">&amp;#39;idealista&amp;#39;&lt;/span>, &lt;span style="color:#e6db74">&amp;#39;all&amp;#39;&lt;/span> }:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> flat_list&lt;span style="color:#f92672">.&lt;/span>extend(scrap_idealista(max_price))
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#66d9ef">if&lt;/span> site &lt;span style="color:#f92672">in&lt;/span> { &lt;span style="color:#e6db74">&amp;#39;fotocasa&amp;#39;&lt;/span>, &lt;span style="color:#e6db74">&amp;#39;all&amp;#39;&lt;/span> }:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> flat_list&lt;span style="color:#f92672">.&lt;/span>extend(scrap_fotocasa(max_price))
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> send_results(flat_list, update, context)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> send_final_message(context, update)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#66d9ef">def&lt;/span> &lt;span style="color:#a6e22e">send_initial_message&lt;/span>(context, update):
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> context&lt;span style="color:#f92672">.&lt;/span>bot&lt;span style="color:#f92672">.&lt;/span>send_message(chat_id&lt;span style="color:#f92672">=&lt;/span>update&lt;span style="color:#f92672">.&lt;/span>effective_chat&lt;span style="color:#f92672">.&lt;/span>id, text&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#e6db74">&amp;#39;Emaidazu minutu bat!&amp;#39;&lt;/span>)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#66d9ef">def&lt;/span> &lt;span style="color:#a6e22e">send_final_message&lt;/span>(context, update):
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> context&lt;span style="color:#f92672">.&lt;/span>bot&lt;span style="color:#f92672">.&lt;/span>send_message(chat_id&lt;span style="color:#f92672">=&lt;/span>update&lt;span style="color:#f92672">.&lt;/span>effective_chat&lt;span style="color:#f92672">.&lt;/span>id, text&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#e6db74">&amp;#39;Hortxe dauzkazu!&amp;#39;&lt;/span>)
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>Essentially, different scraping functions are called based on the executed callback. The &lt;code>context&lt;/code> and &lt;code>update&lt;/code> objects allow you to obtain the bot instance and all the information related to the executed commands (which user executed them, in which chat, group or channel, whether arguments were provided, etc.). In this part, you can also see how simple it is to send a message with a bot using the &lt;code>bot.send_message()&lt;/code> function.&lt;/p>
&lt;p>The interesting part of this section is the &lt;code>send_results()&lt;/code> function, which takes the output generated by the scraping functions (the list of apartments, each with all the mentioned information) and sends it via Telegram.&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-python" data-lang="python">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#66d9ef">def&lt;/span> &lt;span style="color:#a6e22e">send_results&lt;/span>(flat_list: list, update: Update, context: CallbackContext):
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#66d9ef">for&lt;/span> flat &lt;span style="color:#f92672">in&lt;/span> flat_list:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> context&lt;span style="color:#f92672">.&lt;/span>bot&lt;span style="color:#f92672">.&lt;/span>send_photo(chat_id&lt;span style="color:#f92672">=&lt;/span>update&lt;span style="color:#f92672">.&lt;/span>effective_chat&lt;span style="color:#f92672">.&lt;/span>id, caption&lt;span style="color:#f92672">=&lt;/span>flat[&lt;span style="color:#e6db74">&amp;#39;link&amp;#39;&lt;/span>], photo&lt;span style="color:#f92672">=&lt;/span>flat[&lt;span style="color:#e6db74">&amp;#39;image&amp;#39;&lt;/span>])
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> sleep(&lt;span style="color:#ae81ff">1&lt;/span>)
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>This part is also quite straightforward. To send a message, you just need to indicate the chat ID (which is something received in the callbacks to know where the command was called from) and the content you want to send. As seen before, you can send a message with bot.send_message() by providing the chat and the text. In this case, you send the photo of each apartment with bot.send_photo(), specifying the collected image in the photo parameter and the link in the caption parameter.&lt;/p>
&lt;p>With all of this, it&amp;rsquo;s as simple as running it and starting to search for apartments.&lt;/p>
&lt;p>&lt;img src="https://ander94lakx.github.io/static/images/telegram_bot.png" alt="Telegram Bot" title="Telegram bot searching for flats">&lt;/p>
&lt;p>As it is, it seems quite elegant to me. Taking the entire element as an image allows you to see all the information at a glance, and including the link provides access to the listing for more details or direct contact with the landlord. Another option could have been to capture the text and create a list of apartments with their links, but the first approach appears to be one of the most elegant and certainly the simplest of them all.&lt;/p>
&lt;h2 id="part-3-creating-a-telegram-channel-to-send-the-info-to-it">Part 3: creating a Telegram channel to send the info to it&lt;/h2>
&lt;p>Sí, con esto no tengo suficiente. Escribir un comando al bot es demasiado trabajo. Por ello, a parte de tener el bot así, he añadido un metodo para que el bot, cada cierto tiempo, escriba en un canal las ofertas que hay. Esto es basicamente lo msimo que hace por ejemplo el &lt;a href="https://t.me/getmanfred">bot de Manfred&lt;/a> con las ofertas de trabajo, pero con mayor frecuencia. Además, me gusta como en ese bot no va dejando los mensajes de días anteriores, sino que solo está el último mensaje. Así evita que se llene el canal de mierda y deja que haya solo lo que tiene que haber. Por ello, yo lo he hecho igual.&lt;/p>
&lt;p>That is not enough for me. Typing a command to the bot is too much effort. That&amp;rsquo;s why, in addition to having the bot set up this way, I&amp;rsquo;ve added a method for the bot to periodically post offers in a channel. Essentially, this is similar to what, for instance, the &lt;a href="https://t.me/getmanfred">Manfred bot&lt;/a> does with job offers, but with higher frequency. Moreover, I like how that bot doesn&amp;rsquo;t leave messages from previous days; only the latest message remains. This prevents the channel from getting cluttered and keeps only the necessary content. Thus, I&amp;rsquo;ve implemented it the same way.&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-python" data-lang="python">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#66d9ef">def&lt;/span> &lt;span style="color:#a6e22e">update_channel&lt;/span>():
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#75715e"># Get channel and bot info&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#66d9ef">with&lt;/span> open(&lt;span style="color:#e6db74">&amp;#39;token.txt&amp;#39;&lt;/span>) &lt;span style="color:#66d9ef">as&lt;/span> f:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> token &lt;span style="color:#f92672">=&lt;/span> f&lt;span style="color:#f92672">.&lt;/span>read()
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#66d9ef">with&lt;/span> open(&lt;span style="color:#e6db74">&amp;#39;channel_id.txt&amp;#39;&lt;/span>) &lt;span style="color:#66d9ef">as&lt;/span> f:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> channel_id &lt;span style="color:#f92672">=&lt;/span> f&lt;span style="color:#f92672">.&lt;/span>read()
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> bot &lt;span style="color:#f92672">=&lt;/span> telegram&lt;span style="color:#f92672">.&lt;/span>Bot(token&lt;span style="color:#f92672">=&lt;/span>token)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#75715e"># Remove previously sended messages&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> stacked_messages &lt;span style="color:#f92672">=&lt;/span> []
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#66d9ef">with&lt;/span> open(&lt;span style="color:#e6db74">&amp;#39;sent_messages.txt&amp;#39;&lt;/span>, &lt;span style="color:#e6db74">&amp;#39;r&amp;#39;&lt;/span>) &lt;span style="color:#66d9ef">as&lt;/span> f:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#66d9ef">for&lt;/span> line &lt;span style="color:#f92672">in&lt;/span> f&lt;span style="color:#f92672">.&lt;/span>readlines():
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> stacked_messages&lt;span style="color:#f92672">.&lt;/span>append(int(line))
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#66d9ef">while&lt;/span> stacked_messages:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> bot&lt;span style="color:#f92672">.&lt;/span>delete_message(chat_id&lt;span style="color:#f92672">=&lt;/span>channel_id, message_id&lt;span style="color:#f92672">=&lt;/span>stacked_messages&lt;span style="color:#f92672">.&lt;/span>pop())
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#75715e"># Scrap all with the defaul top price&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> flat_list &lt;span style="color:#f92672">=&lt;/span> []
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> flat_list&lt;span style="color:#f92672">.&lt;/span>extend(scrap_idealista(top_price))
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> flat_list&lt;span style="color:#f92672">.&lt;/span>extend(scrap_fotocasa(top_price))
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#75715e"># Send the messages with the info&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#75715e"># Saves the message_id of the messages to be able to delete them on the next one&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> stacked_messages&lt;span style="color:#f92672">.&lt;/span>append(bot&lt;span style="color:#f92672">.&lt;/span>send_message(chat_id&lt;span style="color:#f92672">=&lt;/span>channel_id, text&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#e6db74">&amp;#39;Kaixo! Hamen dauzkazu oraintxe bertan dauden pisuak:&amp;#39;&lt;/span>)&lt;span style="color:#f92672">.&lt;/span>message_id)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#66d9ef">for&lt;/span> flat &lt;span style="color:#f92672">in&lt;/span> flat_list:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> stacked_messages&lt;span style="color:#f92672">.&lt;/span>append(bot&lt;span style="color:#f92672">.&lt;/span>send_photo(chat_id&lt;span style="color:#f92672">=&lt;/span>channel_id, caption&lt;span style="color:#f92672">=&lt;/span>flat[&lt;span style="color:#e6db74">&amp;#39;link&amp;#39;&lt;/span>], photo&lt;span style="color:#f92672">=&lt;/span>flat[&lt;span style="color:#e6db74">&amp;#39;image&amp;#39;&lt;/span>])&lt;span style="color:#f92672">.&lt;/span>message_id)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> sleep(&lt;span style="color:#ae81ff">1&lt;/span>)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> stacked_messages&lt;span style="color:#f92672">.&lt;/span>append(bot&lt;span style="color:#f92672">.&lt;/span>send_message(chat_id&lt;span style="color:#f92672">=&lt;/span>channel_id, text&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#e6db74">&amp;#39;Hortxe dauzkazu!&amp;#39;&lt;/span>)&lt;span style="color:#f92672">.&lt;/span>message_id)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#66d9ef">with&lt;/span> open(&lt;span style="color:#e6db74">&amp;#39;sent_messages.txt&amp;#39;&lt;/span>, &lt;span style="color:#e6db74">&amp;#39;w&amp;#39;&lt;/span>) &lt;span style="color:#66d9ef">as&lt;/span> f:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#66d9ef">for&lt;/span> message &lt;span style="color:#f92672">in&lt;/span> stacked_messages:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> f&lt;span style="color:#f92672">.&lt;/span>write(str(message) &lt;span style="color:#f92672">+&lt;/span> &lt;span style="color:#e6db74">&amp;#39;&lt;/span>&lt;span style="color:#ae81ff">\n&lt;/span>&lt;span style="color:#e6db74">&amp;#39;&lt;/span>)
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>I know, this is not the cleanest thing you&amp;rsquo;ve seen in your life. It&amp;rsquo;s basically more of the same but managing the messages that have been sent. Each sent message has a &lt;code>message_id&lt;/code>, which is what allows later to be able to delete them. This function basically deletes whatever has been written before in the channel, scrapes the information, sends the information, and saves the &lt;code>message_id&lt;/code> to be able to delete the messages next time. It saves those IDs in a file so that, if the bot crashes, they won&amp;rsquo;t be lost and can be deleted when it&amp;rsquo;s restarted, thus not leaving garbage in the channel.&lt;/p>
&lt;p>In this case, it&amp;rsquo;s necessary to create an instance of &lt;code>Bot&lt;/code> since it&amp;rsquo;s not received from anywhere. In addition to this, it&amp;rsquo;s necessary to have the ID of the chat or channel where you want to write. There are many bots that allow you to obtain those IDs.&lt;/p>
&lt;p>The idea is to have the script running 24/7 and, in this way, the bot is always ready. On one hand, with the handlers listening, which is done with &lt;code>updater.start_polling()&lt;/code> as seen before. On the other hand, there needs to be a way to execute the &lt;code>update_channel()&lt;/code> function periodically. For this, we can use &lt;code>schedule&lt;/code>, a library that allows you to schedule tasks easily. To install it, use &lt;code>pip&lt;/code> and you&amp;rsquo;re done.&lt;/p>
&lt;p>To use it to execute &lt;code>update_channel()&lt;/code> at certain intervals, just add the following at the end of the &lt;code>init()&lt;/code> function:&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-python" data-lang="python">&lt;span style="display:flex;">&lt;span>schedule&lt;span style="color:#f92672">.&lt;/span>every()&lt;span style="color:#f92672">.&lt;/span>hour&lt;span style="color:#f92672">.&lt;/span>at(&lt;span style="color:#e6db74">&amp;#34;:00&amp;#34;&lt;/span>)&lt;span style="color:#f92672">.&lt;/span>do(update_channel)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#66d9ef">while&lt;/span> &lt;span style="color:#66d9ef">True&lt;/span>:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> schedule&lt;span style="color:#f92672">.&lt;/span>run_pending()
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> sleep(&lt;span style="color:#ae81ff">1&lt;/span>)
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>As you can see, it&amp;rsquo;s very straightforward to use and the code explains itself. There&amp;rsquo;s no need to worry about the &lt;code>while True&lt;/code> loop. The polling of callbacks runs in separate threads, so this doesn&amp;rsquo;t interfere. This keeps it indefinitely checking whether it needs to launch any tasks.&lt;/p>
&lt;p>With all of this in place, all that&amp;rsquo;s left is to let it run somewhere. These kinds of things are perfect for a Raspberry Pi or something similar. It can also be set up on a VPS or wherever suits. The only thing to keep in mind is that it either needs a display or some library like the one mentioned to emulate it. Additionally, the browser that will be used must be installed.&lt;/p>
&lt;p>You can also add more websites for scraping, it&amp;rsquo;s easily scalable. In my case, I use Idealista and Fotocasa, but you can simply add more scraping functions. Obviously, how you retrieve the information will vary from site to site.&lt;/p>
&lt;h2 id="conclusions">Conclusions&lt;/h2>
&lt;p>Creating a bot of this kind is a straightforward task, as you can see. The real challenge, however, lies in finding a decent flat that doesn&amp;rsquo;t cost an arm and a leg. That&amp;rsquo;s where the true difficulty lies.&lt;/p>
&lt;p>Developing a bot to retrieve updated information can be very useful. Using web scraping instead of APIs has its advantages. First and foremost, most websites don&amp;rsquo;t offer APIs, so in those cases, there&amp;rsquo;s no other option. Even in cases where APIs are available, they might have limitations. The beauty of web scraping is that it allows you to gather &lt;strong>exactly what you want, in the way you want it&lt;/strong>. And let no one deceive you; as long as you&amp;rsquo;re not hammering the website or extracting data massively, there&amp;rsquo;s no wrongdoing here.&lt;/p>
&lt;p>I hope I&amp;rsquo;ve explained myself well and that if you&amp;rsquo;re reading this, it sparks your curiosity to tinker with these topics. As for me, I&amp;rsquo;m not going to stop exploring :)&lt;/p>
&lt;p>Lastly, here&amp;rsquo;s the &lt;a href="https://github.com/ander94lakx/pisu-bot">GitHub repository&lt;/a> with the complete code. As always, feel free to do whatever you want with it.&lt;/p>
&lt;p>And remember: &lt;em>&lt;strong>Scraping is not a crime!&lt;/strong>&lt;/em>&lt;/p></content></item><item><title>How to download images from an Instagram profile with Python and web scrapping</title><link>https://ander94lakx.github.io/blog/2020-04-25-instagram-bot-python/</link><pubDate>Sat, 25 Apr 2020 00:00:00 +0000</pubDate><author>ander@protonmail.com (Ander Granado)</author><guid>https://ander94lakx.github.io/blog/2020-04-25-instagram-bot-python/</guid><description>Instagram is the social network to showing off. It&amp;rsquo;s probably the social network I use the most. I&amp;rsquo;m too young to actively use Facebook and too old to even consider creating TikTok (if you see it happening, I give you permission to kill me). I also use twitter, but more as a &amp;ldquo;news&amp;rdquo; provider, but I don&amp;rsquo;t post anything on that one.
So all my posts tend to go to Instagram.</description><content>&lt;p>Instagram is the social network to showing off. It&amp;rsquo;s probably the social network I use the most. I&amp;rsquo;m too young to actively use Facebook and too old to even consider creating TikTok (if you see it happening, I give you permission to kill me). I also use twitter, but more as a &amp;ldquo;news&amp;rdquo; provider, but I don&amp;rsquo;t post anything on that one.&lt;/p>
&lt;p>So all my posts tend to go to Instagram. Over the years I have found that it has become a kind of personal milestone diary. Above the photos from my travels you might see photos from when I got my degree, from when I lived in Madrid and was in a videogame studio as a game programmer, or from good times with friends. Although the quality of the images may not be the best, I like to go there from time to time and see all those trips and moments.&lt;/p>
&lt;p>Still, I&amp;rsquo;m a techie and I know that the only way to keep your information safe is to have a copy of it safe by yourself. So I&amp;rsquo;ve been thinking for a while about making a script that would allow me to download all my profile pictures. I could also use this to refresh a bit my Python knowledge and practice some web scraping.&lt;/p>
&lt;h1 id="web-scrapping-with-selenium">Web Scrapping with Selenium&lt;/h1>
&lt;p>Some time ago I tried to implement i, and failed, mainly because I tried to download, parse and search the pages manually. The problem is that a web page does not consist only of a single HTML resource, and doing it by hand implies getting all the resources that make up a page. So I put it aside. That was until the other day, when by chance I found a &lt;a href="https://www.youtube.com/watch?v=d2GBO_QjRlo">video&lt;/a> in which someone programmed a bot for Instagram to see the people who had unfollowed him. I didn&amp;rsquo;t care about the followers, but I wanted to see how he did it.&lt;/p>
&lt;p>When I saw how he did it I saw that he was using a library called &lt;a href="https://www.selenium.dev/">Selenium&lt;/a>, which is a tool that allows you to automate actions inside a browser, mainly to automate functional test and things like that. For me, libraries like that are basically the holy grail of Web Scrapping, it saves you all the hassle of making the requests, filtering the pages, searching for tags, etc. So I downloaded the WebDriver for Firefox (it&amp;rsquo;s the bridge between the library and the browser), installed the Python library and based on the video I started programming.&lt;/p>
&lt;h1 id="log-in-on-instagram">Log in on Instagram&lt;/h1>
&lt;p>&lt;img src="https://ander94lakx.github.io/static/images/ig-login.png" alt="Instagram login website">&lt;/p>
&lt;p>The first thing to do is to log in to the page. To do this, we need to do the following:&lt;/p>
&lt;ol>
&lt;li>Get the page. As we are not logged in, the page that will appear will be the login page.&lt;/li>
&lt;li>Obtain the user and password fields and fill them.&lt;/li>
&lt;li>Click on the &lt;em>Log in&lt;/em> button.&lt;/li>
&lt;/ol>
&lt;p>All this, done programmatically in Python looks as follows:&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-python" data-lang="python">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#66d9ef">class&lt;/span> &lt;span style="color:#a6e22e">InstaBot&lt;/span>:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#66d9ef">def&lt;/span> __init__(self, username, pw):
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> self&lt;span style="color:#f92672">.&lt;/span>driver &lt;span style="color:#f92672">=&lt;/span> webdriver&lt;span style="color:#f92672">.&lt;/span>Firefox(executable_path&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#e6db74">&amp;#34;./geckodriver.exe&amp;#34;&lt;/span>)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> self&lt;span style="color:#f92672">.&lt;/span>username &lt;span style="color:#f92672">=&lt;/span> username
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> self&lt;span style="color:#f92672">.&lt;/span>driver&lt;span style="color:#f92672">.&lt;/span>get(&lt;span style="color:#e6db74">&amp;#34;https://instagram.com&amp;#34;&lt;/span>)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> sleep(&lt;span style="color:#ae81ff">2&lt;/span>)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> self&lt;span style="color:#f92672">.&lt;/span>driver&lt;span style="color:#f92672">.&lt;/span>find_element_by_xpath(&lt;span style="color:#e6db74">&amp;#34;//input[@name=&lt;/span>&lt;span style="color:#ae81ff">\&amp;#34;&lt;/span>&lt;span style="color:#e6db74">username&lt;/span>&lt;span style="color:#ae81ff">\&amp;#34;&lt;/span>&lt;span style="color:#e6db74">]&amp;#34;&lt;/span>)\
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">.&lt;/span>send_keys(username)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> self&lt;span style="color:#f92672">.&lt;/span>driver&lt;span style="color:#f92672">.&lt;/span>find_element_by_xpath(&lt;span style="color:#e6db74">&amp;#34;//input[@name=&lt;/span>&lt;span style="color:#ae81ff">\&amp;#34;&lt;/span>&lt;span style="color:#e6db74">password&lt;/span>&lt;span style="color:#ae81ff">\&amp;#34;&lt;/span>&lt;span style="color:#e6db74">]&amp;#34;&lt;/span>)\
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">.&lt;/span>send_keys(pw)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> self&lt;span style="color:#f92672">.&lt;/span>driver&lt;span style="color:#f92672">.&lt;/span>find_element_by_xpath(&lt;span style="color:#e6db74">&amp;#39;//button[@type=&amp;#34;submit&amp;#34;]&amp;#39;&lt;/span>)\
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">.&lt;/span>click()
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> sleep(&lt;span style="color:#ae81ff">4&lt;/span>)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> self&lt;span style="color:#f92672">.&lt;/span>driver&lt;span style="color:#f92672">.&lt;/span>find_element_by_xpath(&lt;span style="color:#e6db74">&amp;#34;//button[contains(text(), &amp;#39;Ahora no&amp;#39;)]&amp;#34;&lt;/span>)\
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">.&lt;/span>click()
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> sleep(&lt;span style="color:#ae81ff">2&lt;/span>)
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>As can be seen, I&amp;rsquo;ve put the code in the constructor of a class, which is the class where I&amp;rsquo;m going to implement everything. It is in the constructor because, whatever you want to do, you always need to login. The &lt;code>sleep()&lt;/code> is necessary because the page needs time to load.&lt;/p>
&lt;p>If you run that, you will see that it is the same process that anyone would do to log into Instagram, but automated. You will even be able to see it live in the isolated browser that opens the WebDriver. I&amp;rsquo;m not going to dig into each function, as I think the names are pretty self-explanatory and it&amp;rsquo;s easy to understand what each one is doing.&lt;/p>
&lt;h1 id="get-all-instagram-posts">Get all Instagram posts&lt;/h1>
&lt;p>&lt;img src="https://ander94lakx.github.io/static/images/ig-posts.png" alt="Instagram posts">&lt;/p>
&lt;p>After that, my idea was to go to the profile page, grab each link to each post and from each one grab the URL where the image is located. I&amp;rsquo;ve already done it manually, so I know that Instagram images can be grabbed by inspecting the HTML for the URL of the image, the URL of a post is usually something like this, which is in the &lt;code>&amp;lt;img&amp;gt;&lt;/code> tag nested by several &lt;code>&amp;lt;div&amp;gt;&lt;/code>:&lt;/p>
&lt;p>&lt;img src="https://ander94lakx.github.io/static/images/g-image-post-url.png" alt="URL of the image of an Instagram post">&lt;/p>
&lt;p>But before we get to that, we need to grab the links to all the posts, so we can find the image link for each of them. The links of an Instagram post have the format &lt;code>https://www.instagram.com/p/B--N-oBKdPL/&lt;/code>. To get them, once you get to the profile page, we have to scroll down and look for these links.&lt;/p>
&lt;p>My initial idea was to scroll all the way down and then look for all the links. The problem is that the profile page only keeps a certain number of posts loaded in the page and, as you scroll down and load new ones, the previous ones disappear. In my experience, it usually keeps around 30 posts loaded. Therefore, what should be done is to scroll down and get the links. To do this I have created the function &lt;code>get_pictures_links()&lt;/code>, which contains the following:&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-python" data-lang="python">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#66d9ef">def&lt;/span> &lt;span style="color:#a6e22e">get_pictures_links&lt;/span>(self):
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> self&lt;span style="color:#f92672">.&lt;/span>driver&lt;span style="color:#f92672">.&lt;/span>find_element_by_xpath(&lt;span style="color:#e6db74">&amp;#34;//a[contains(@href,&amp;#39;/&lt;/span>&lt;span style="color:#e6db74">{}&lt;/span>&lt;span style="color:#e6db74">&amp;#39;)]&amp;#34;&lt;/span>&lt;span style="color:#f92672">.&lt;/span>format(self&lt;span style="color:#f92672">.&lt;/span>username))\
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">.&lt;/span>click()
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> sleep(&lt;span style="color:#ae81ff">2&lt;/span>)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> links &lt;span style="color:#f92672">=&lt;/span> []
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> last_height &lt;span style="color:#f92672">=&lt;/span> self&lt;span style="color:#f92672">.&lt;/span>driver&lt;span style="color:#f92672">.&lt;/span>execute_script(&lt;span style="color:#e6db74">&amp;#34;return document.body.scrollHeight&amp;#34;&lt;/span>)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#66d9ef">while&lt;/span> &lt;span style="color:#66d9ef">True&lt;/span>:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> self&lt;span style="color:#f92672">.&lt;/span>driver&lt;span style="color:#f92672">.&lt;/span>execute_script(&lt;span style="color:#e6db74">&amp;#34;window.scrollTo(0, document.body.scrollHeight);&amp;#34;&lt;/span>)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> sleep(&lt;span style="color:#ae81ff">2&lt;/span>)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> links_elements &lt;span style="color:#f92672">=&lt;/span> self&lt;span style="color:#f92672">.&lt;/span>driver&lt;span style="color:#f92672">.&lt;/span>find_elements_by_xpath(&lt;span style="color:#e6db74">&amp;#39;//a[contains(@href,&amp;#34;p/&amp;#34;)]&amp;#39;&lt;/span>)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#66d9ef">for&lt;/span> elem &lt;span style="color:#f92672">in&lt;/span> links_elements:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> links&lt;span style="color:#f92672">.&lt;/span>append(elem&lt;span style="color:#f92672">.&lt;/span>get_attribute(&lt;span style="color:#e6db74">&amp;#39;href&amp;#39;&lt;/span>))
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> new_height &lt;span style="color:#f92672">=&lt;/span> self&lt;span style="color:#f92672">.&lt;/span>driver&lt;span style="color:#f92672">.&lt;/span>execute_script(&lt;span style="color:#e6db74">&amp;#34;return document.body.scrollHeight&amp;#34;&lt;/span>)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#66d9ef">if&lt;/span> new_height &lt;span style="color:#f92672">==&lt;/span> last_height:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#66d9ef">break&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> last_height &lt;span style="color:#f92672">=&lt;/span> new_height
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> links &lt;span style="color:#f92672">=&lt;/span> list(set(links))
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#66d9ef">return&lt;/span> links
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>There are several things to note in the above function:&lt;/p>
&lt;ul>
&lt;li>Scrolling is done using JavaScript. To execute JavaScript code on the web, the &lt;code>execute_script()&lt;/code> function is used.&lt;/li>
&lt;li>The height counter is used to know when to stop scrolling down. If it remains in the same position when scrolling as in the previous scroll, it stops.&lt;/li>
&lt;li>To search for links to posts, look for the corresponding &lt;code>&amp;lt;a&amp;gt;&lt;/code> tags. In this case we look for a link tag containing &lt;code>/p&lt;/code> in the &lt;code>href&lt;/code> attribute.
&lt;ul>
&lt;li>Once we have obtained the tag or, as in this case, the list of tags that meet the criteria, we obtain the attributes themselves, which are the URLs we want. These are saved in the list.&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>Because of the way the grid works, it is normal to end up picking up repeated values, as the tags are unloaded over time, but are kept for several scrolls. Therefore, at the end of the scroll, you do a &lt;code>list(set(links))&lt;/code> to remove duplicates (go to a set, which cannot contain repeats, and then to a list to leave it as before). Doing that leaves the elements out of order, but in this case it doesn&amp;rsquo;t matter. Of the solutions I found on &lt;a href="https://stackoverflow.com/a/7961393">StackOverflow&lt;/a>, that seemed to me to be the cleanest and most adequate for this case.&lt;/li>
&lt;/ul>
&lt;h1 id="get-the-_permalinks_-to-the-images">Get the &lt;em>permalinks&lt;/em> to the images&lt;/h1>
&lt;p>With all the posts, the only thing left to do is to open them one by one and look for the images they contain. To do this, I have created the function &lt;code>get_picture()&lt;/code>, to which I pass each of the links I have previously obtained and look for the image to download it.&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-python" data-lang="python">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#66d9ef">def&lt;/span> &lt;span style="color:#a6e22e">get_picture&lt;/span>(self, link):
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> self&lt;span style="color:#f92672">.&lt;/span>driver&lt;span style="color:#f92672">.&lt;/span>get(link)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> sleep(&lt;span style="color:#ae81ff">2&lt;/span>)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#66d9ef">try&lt;/span>:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> img_element &lt;span style="color:#f92672">=&lt;/span> self&lt;span style="color:#f92672">.&lt;/span>driver&lt;span style="color:#f92672">.&lt;/span>find_element_by_xpath(&lt;span style="color:#e6db74">&amp;#39;//img[contains(@class,&amp;#34;FFVAD&amp;#34;)]&amp;#39;&lt;/span>)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> url &lt;span style="color:#f92672">=&lt;/span> img_element&lt;span style="color:#f92672">.&lt;/span>get_attribute(&lt;span style="color:#e6db74">&amp;#39;src&amp;#39;&lt;/span>)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> time_element &lt;span style="color:#f92672">=&lt;/span> self&lt;span style="color:#f92672">.&lt;/span>driver&lt;span style="color:#f92672">.&lt;/span>find_elements_by_tag_name(&lt;span style="color:#e6db74">&amp;#39;time&amp;#39;&lt;/span>)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> timestamp &lt;span style="color:#f92672">=&lt;/span> time_element[&lt;span style="color:#ae81ff">0&lt;/span>]&lt;span style="color:#f92672">.&lt;/span>get_attribute(&lt;span style="color:#e6db74">&amp;#39;datetime&amp;#39;&lt;/span>)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#66d9ef">if&lt;/span> url &lt;span style="color:#f92672">is&lt;/span> &lt;span style="color:#f92672">not&lt;/span> &lt;span style="color:#66d9ef">None&lt;/span> &lt;span style="color:#f92672">and&lt;/span> timestamp &lt;span style="color:#f92672">is&lt;/span> &lt;span style="color:#f92672">not&lt;/span> &lt;span style="color:#66d9ef">None&lt;/span>:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> timestamp &lt;span style="color:#f92672">=&lt;/span> timestamp&lt;span style="color:#f92672">.&lt;/span>replace(&lt;span style="color:#e6db74">&amp;#39;:&amp;#39;&lt;/span>, &lt;span style="color:#e6db74">&amp;#39;-&amp;#39;&lt;/span>)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> timestamp &lt;span style="color:#f92672">=&lt;/span> timestamp&lt;span style="color:#f92672">.&lt;/span>replace(&lt;span style="color:#e6db74">&amp;#39;.&amp;#39;&lt;/span>, &lt;span style="color:#e6db74">&amp;#39;-&amp;#39;&lt;/span>)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> print(url)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> urllib&lt;span style="color:#f92672">.&lt;/span>request&lt;span style="color:#f92672">.&lt;/span>urlretrieve(url, timestamp &lt;span style="color:#f92672">+&lt;/span> &lt;span style="color:#e6db74">&amp;#39;.jpg&amp;#39;&lt;/span>)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#66d9ef">except&lt;/span>:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#66d9ef">pass&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>Ignoring that I don&amp;rsquo;t deal with the exception (and I should), this is where the magic really happens and where there are the most problems. At the moment the easiest way I&amp;rsquo;ve found to get the tag that contains the actual image is to search for it via its class. The names of all the classes used in the HTML of the Instagram website are minimized or obfuscated. But, based on the testing I&amp;rsquo;ve been doing, they don&amp;rsquo;t change over time, so I&amp;rsquo;m using that class name. Once you know how to do it, it&amp;rsquo;s very easy to find the tag with Seleniun and get the URL.&lt;/p>
&lt;p>Also, to save the images I also get the timestamp of when the post was published. From there, you just need to download the image with &lt;code>urllib&lt;/code>.&lt;/p>
&lt;h1 id="summary">Summary&lt;/h1>
&lt;p>The bot has many parts with room for improvement. So far I haven&amp;rsquo;t talked about posts that contain a video or posts that contain several images. I will improve it over time, but I think that as it stands it is a good way to understand how to do basic web scraping. I&amp;rsquo;m going to leave the code in a &lt;a href="https://github.com/ander94lakx/InstaBot">GitHub repository&lt;/a>, where you will be able to see these improvements.&lt;/p>
&lt;h1 id="what-about-the-instagram-api">What about the Instagram API?&lt;/h1>
&lt;p>At this point, perhaps someone is wondering why do all this and not use Instagram&amp;rsquo;s API directly. On the one hand, I know there is a new API, but I don&amp;rsquo;t know it. My goal is to try to do the same thing that this tool does but with this API. The one I know is the previous API, which I think is limited and will soon be obsolete.&lt;/p>
&lt;p>Still, the goal of this bot is not to depend on whether Instagram is going to allow you to get those images or not. After all, once you&amp;rsquo;re logged into the app, you can technically grab as many images as you want, so you should be able to do it programmatically as well.&lt;/p>
&lt;p>In the end, it&amp;rsquo;s not about whether Instagram will let you do it or not, it&amp;rsquo;s about: if you can, why not?&lt;/p></content></item></channel></rss>